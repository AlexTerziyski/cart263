# Final-Project
Alex Terziyski

 * This project utilizes the p5.js library and Mediapipe Hands model to interact with hand gestures captured via webcam. 
 * It synthesizes speech based on hand movements, mapping hand position to pitch and utilizing different voices. 
 * Users can input a word by typing in the provided input field and pressing enter. The word will be repeated continuously 
 * until the user enters a new word. Users can explore different synthesizer and text effects by moving their hands in 
 * various positions relative to the detected landmarks. Different effects, such as high pitch, low pitch, faster pronunciation, 
 * and slower pronunciation, are activated by hovering the index finger over corresponding ellipses on the screen. Additionally, 
 * hovering the index finger over the "Language Randomizer" ellipse changes the voice synthesizer randomly, providing an 
 * interactive experience for users to experiment with speech synthesis using hand gestures.
